{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Imported Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from itertools import permutations\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Generation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassiopeia.PNG\n",
      "Gemini.PNG\n",
      "Hercules.PNG\n",
      "Leo.PNG\n",
      "Libra.PNG\n",
      "Perseus.PNG\n",
      "Phoenix.PNG\n",
      "UrsaMinor.PNG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "def skew_image(image,direction):\n",
    "    \n",
    "    factor = random.uniform(0.01,0.05)\n",
    "    \n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    \n",
    "    #initial coords of the 4 corners, ahseb fil google lens taghzel il kantunieri tal karta\n",
    "    points1 = np.float32([[0, 0], [image.shape[1], 0], [0, image.shape[0]], [image.shape[1], image.shape[0]]])\n",
    "    \n",
    "    #jaghzel new anchor points tal corners to skew towards\n",
    "    if direction == 1:\n",
    "        points2 = np.float32([\n",
    "                    [0, 0],\n",
    "                        [w, 0],\n",
    "                        [int(w * factor), h],\n",
    "                        [w - int(w * factor), h]\n",
    "                        ])\n",
    "    elif direction == 2:\n",
    "        points2 = np.float32([\n",
    "                    [0, 0],\n",
    "                        [w, int(h * factor)],\n",
    "                        [0, h],\n",
    "                        [w, int(h - h * factor)]\n",
    "                        ])\n",
    "    elif direction == 3:\n",
    "        points2 = np.float32([\n",
    "                    [0, int(h * factor)],\n",
    "                        [w, 0],\n",
    "                        [0, int(h - h * factor)],\n",
    "                        [w, h]\n",
    "                        ])\n",
    "    else:\n",
    "        points2 = np.float32([\n",
    "                        [int(w * factor), 0],\n",
    "                        [w - int(w * factor), 0],\n",
    "                        [0, h],\n",
    "                        [w, h]\n",
    "                        ])\n",
    "    #finds the transformation matrix that transforms the image depending on anchor points   \n",
    "    transform_matrix = cv2.getPerspectiveTransform(points1, points2)\n",
    "    \n",
    "    #warps the perspective of the image based on the above transformation matrix\n",
    "    return cv2.warpPerspective(image, transform_matrix, (w, h), flags = cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def noise(image):\n",
    "    \n",
    "    \n",
    "    gauss = np.random.normal(0,0.1**0.2,image.size)\n",
    "    gauss = gauss.reshape(image.shape[0],image.shape[1],image.shape[2]).astype('uint8')\n",
    "    return cv2.add(image,gauss)\n",
    "    \n",
    "    \n",
    "\n",
    "for constellation in os.listdir(\"Constellations\"):\n",
    "    \n",
    "    print(constellation)\n",
    "    \n",
    "    for x in range(0,20):\n",
    "\n",
    "        new_image = cv2.imread(\"Constellations/\"+constellation,1)\n",
    "\n",
    "        #contrast\n",
    "        alpha = random.uniform(1,2)\n",
    "        \n",
    "        #brightness\n",
    "        beta = random.randint(-20,15)\n",
    "        new_image = cv2.convertScaleAbs(new_image, alpha=alpha, beta=beta)\n",
    "\n",
    "        new_image = cv2.copyMakeBorder(new_image,new_image.shape[0]//4,new_image.shape[0]//4,new_image.shape[1]//4,new_image.shape[1]//4,cv2.BORDER_CONSTANT,value = 0)\n",
    "\n",
    "\n",
    "        #new_image = skew_image(new_image, random.randint(1,4))\n",
    "\n",
    "        angle = random.randint(1,360)\n",
    "        new_image = rotate_image(new_image,angle)\n",
    "     \n",
    "        cv2.imwrite('Dataset/'+constellation.split(\".\")[0]+str(x)+'.png', new_image) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Template Database </h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cassiopeia.PNG\n",
      "Gemini.PNG\n",
      "Hercules.PNG\n",
      "Leo.PNG\n",
      "Libra.PNG\n",
      "Perseus.PNG\n",
      "Phoenix.PNG\n",
      "UrsaMinor.PNG\n"
     ]
    }
   ],
   "source": [
    "def binarizeImg(image,threshold):\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.blur(gray,(4,4))\n",
    "        \n",
    "    ret,binary = cv2.threshold(blurred,threshold,255,cv2.THRESH_BINARY++cv2.THRESH_OTSU)\n",
    "   \n",
    "    return binary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for line_image in os.listdir(\"Constellations\"):\n",
    "    \n",
    "    print(line_image)\n",
    "    \n",
    "    \n",
    "    image = cv2.imread(\"Constellations/\"+line_image,1)\n",
    "    \n",
    "    \n",
    "    binarized = binarizeImg(image,150)\n",
    "    \n",
    "    cv2.imwrite('TemplateDataset/'+line_image, binarized) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Pre-Processing Test Image</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image,threshold):\n",
    "   \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    blurred = cv2.blur(gray,(4,4))\n",
    "\n",
    "    ret,binary = cv2.threshold(gray,threshold,255,cv2.THRESH_BINARY)\n",
    "   \n",
    "    return binary\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "for data_image in os.listdir(\"Dataset\"):\n",
    "        \n",
    "    image = cv2.imread(\"Dataset/\"+data_image,1)\n",
    "    \n",
    "    binarized = preprocessing(image,150)\n",
    "    \n",
    "    cv2.imwrite('ProcessedDataset/'+data_image, binarized) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Contour Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from a binary image, extract all the contours and return the largest contour object\n",
    "def get_largest_contour(image):\n",
    "\n",
    "    contours, hierarchy= cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n",
    "\n",
    "    return sorted_contours[0]\n",
    "\n",
    "    \n",
    "#returns a sorted list, by area starting with the largest, of the centres of the contours\n",
    "def findFourLargestStar(binary_image):\n",
    "    \n",
    "    contours, hierarchy= cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "    sorted_contours= sorted(contours, key=cv2.contourArea, reverse= True)\n",
    "\n",
    "    \n",
    "    to_draw = binary_image.copy()\n",
    "    to_draw = cv2.cvtColor(to_draw, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    \n",
    "    #a debugging line used to visualise the four brightest stars that were selected\n",
    "    '''largest_item= sorted_contours[0]\n",
    "    second_item = sorted_contours[1]\n",
    "    third_item= sorted_contours[2]\n",
    "    fourth_item= sorted_contours[3]        \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    cv2.drawContours(to_draw, largest_item, -1, (0,0,255),10)\n",
    "    cv2.drawContours(to_draw, second_item, -1, (255,0,0),10)\n",
    "    cv2.drawContours(to_draw, third_item, -1, (0,255,0),10)\n",
    "    cv2.drawContours(to_draw, fourth_item, -1, (255,255,0),10)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('Largest Object', to_draw)'''\n",
    "    \n",
    "    contour_centres = []\n",
    "    \n",
    "    for contour in sorted_contours:\n",
    "        #using image moments to determine the centre of a contour for each contour object\n",
    "        M = cv2.moments(contour)\n",
    "        \n",
    "        if  M[\"m00\"] == 0:\n",
    "            break\n",
    "        \n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "        contour_centres.append( (cX,cY) )\n",
    "    \n",
    "    return contour_centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Contour Matching</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contourMatching(destinationStars,sourceStars,testImage,templateImage):\n",
    "    #initialises the four corresponding points between the two images\n",
    "    \n",
    "    pts_source = np.array([sourceStars[0],sourceStars[1],sourceStars[2],sourceStars[3]])\n",
    "    \n",
    "    pts_destination = np.array([destinationStars[0],destinationStars[1],destinationStars[2],destinationStars[3]]) \n",
    "    \n",
    "    #find the 3d transformation matrix that maps the first set of points onto the next\n",
    "    h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "    \n",
    "    #perfroms the transformation on the template image\n",
    "    rotated_template = cv2.warpPerspective(templateImage, h, (testImage.shape[1],testImage.shape[0]))\n",
    "       \n",
    "    rot_temp_stars = findFourLargestStar(rotated_template)\n",
    "   \n",
    "    largestStar = get_largest_contour(rotated_template)\n",
    "    \n",
    "    #calculates the differnce between the largest contours found in each object, if they are the same image, will be 0.\n",
    "    #therefore a closer image would have a smaller value.\n",
    "    \n",
    "    matching = cv2.matchShapes(largestStar,get_largest_contour(testImage),cv2.CONTOURS_MATCH_I1,0.0)\n",
    "    return matching\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Star Positioning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starPositions(destinationStars,sourceStars,testImage,templateImage):\n",
    "    \n",
    "    pts_source = np.array([sourceStars[0],sourceStars[1],sourceStars[2],sourceStars[3]])\n",
    "    \n",
    "    pts_destination = np.array([destinationStars[0],destinationStars[1],destinationStars[2],destinationStars[3]]) \n",
    "    \n",
    "    h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "\n",
    "    rotated_template = cv2.warpPerspective(templateImage, h, (testImage.shape[1],testImage.shape[0]))\n",
    "    \n",
    "    \n",
    "    rot_temp_stars = findFourLargestStar(rotated_template)\n",
    "   \n",
    "    largestStar = rot_temp_stars[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''    \n",
    "    to_draw_original = testImage.copy()\n",
    "    to_draw_original = cv2.cvtColor(to_draw_original, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    to_draw_temp = rotated_template.copy()\n",
    "    to_draw_temp = cv2.cvtColor(to_draw_temp, cv2.COLOR_GRAY2BGR)'''\n",
    "       \n",
    "    #print(cX,cY)\n",
    "    \n",
    "    confidence = []\n",
    "    \n",
    "    max_no_of_stars = min(len(rot_temp_stars),len(destinationStars))\n",
    "    colours = [(255,0,0),(0,255,0),(0,0,255),(255,255,0),(255,255,255),(255,0,255),(0,255,255)]\n",
    "    for x in range(0,max_no_of_stars):\n",
    "        \n",
    "        \n",
    "        #old debugging functions that helped determine the correct matching of the stars, these do not work anymore since no \n",
    "        #longer using whole contours but rather only the centres.\n",
    "        \n",
    "        '''colour = random.randint(50,255)\n",
    "        cv2.drawContours(to_draw_original, destinationStars[x], -1, (colour,colour,colour),10)\n",
    "        cv2.drawContours(to_draw_temp, rot_temp_stars[x], -1, (colour,colour,colour),10)\n",
    "        '''\n",
    "        \n",
    "        lit = checkNeighbourhood(rot_temp_stars[x],testImage)\n",
    "        confidence.append(lit)\n",
    "    \n",
    "    norm_confidence = confidence.count(255)/len(confidence)\n",
    "        \n",
    "    \n",
    "    \n",
    "    final = cv2.hconcat([testImage,rotated_template])\n",
    "       \n",
    "    \n",
    "    #displays the original test image alongside the transformed template\n",
    "    '''\n",
    "    cv2.imshow(\"Rotated Template\",final)\n",
    "    cv2.waitKey(0)'''\n",
    "   \n",
    "    return norm_confidence\n",
    "    \n",
    "#will check around the neighbourhood of a pixel to see if there is a white pixel, scan range size set by scan.\n",
    "def checkNeighbourhood(coord,testImage):\n",
    "    \n",
    "    \n",
    "    scan = 5\n",
    "    \n",
    "    for x in range(-scan,scan):\n",
    "        for y in range(-scan,scan):\n",
    "            \n",
    "            if coord[1]+y >= testImage.shape[0] or coord[1]+y < 0:\n",
    "                break\n",
    "                \n",
    "            if coord[0]+x >= testImage.shape[1] or coord[0]+x < 0:\n",
    "                break\n",
    "            \n",
    "            if testImage[coord[1]+y,coord[0]+x] == 255:\n",
    "                return 255\n",
    "            \n",
    "    return 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def permutationsTemplateMatching(destinationStars,sourceStars,testImage,templateImage):\n",
    "    \n",
    "    \n",
    "    pts_source = np.array([sourceStars[0],sourceStars[1],sourceStars[2],sourceStars[3]])\n",
    "    \n",
    "    \n",
    "    permutations_list = list(permutations([0,1,2,3]))\n",
    "    \n",
    "    prev_best = 9999\n",
    "    #loops through all permutations, all possible configurations of the top 4 stars being in first second third or fourth\n",
    "    for z in range(0,len(permutations_list)):\n",
    "        first = permutations_list[z][0]\n",
    "        second = permutations_list[z][1]  \n",
    "        third = permutations_list[z][2]\n",
    "        fourth = permutations_list[z][3]\n",
    "        pts_destination = np.array([destinationStars[first],destinationStars[second],destinationStars[third],destinationStars[fourth]]) \n",
    "        h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "\n",
    "        rotated_template = cv2.warpPerspective(templateImage, h, (testImage.shape[1],testImage.shape[0]))\n",
    "        \n",
    "    \n",
    "        \n",
    "        rot_temp_stars = findFourLargestStar(rotated_template)\n",
    "        \n",
    "        \n",
    "        #transforms the template at each iteration and performs the contour mtaching to see which produces the least distortion\n",
    "        largestStar = get_largest_contour(rotated_template)\n",
    "        matching = cv2.matchShapes(largestStar,get_largest_contour(testImage),cv2.CONTOURS_MATCH_I1,0.0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if matching < prev_best:\n",
    "            prev_best = matching\n",
    "            best_index = z\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "    #obtains the transformed template that produced the least distortion \n",
    "    first = permutations_list[best_index][0]\n",
    "    second = permutations_list[best_index][1]\n",
    "    third = permutations_list[best_index][2]\n",
    "    fourth = permutations_list[best_index][3]\n",
    "    pts_destination = np.array([destinationStars[first],destinationStars[second],destinationStars[third],destinationStars[fourth]]) \n",
    "    h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "\n",
    "    rotated_template = cv2.warpPerspective(templateImage, h, (testImage.shape[1],testImage.shape[0]))\n",
    "\n",
    "    \n",
    "    rot_temp_stars = findFourLargestStar(rotated_template)\n",
    "    \n",
    "    largestStar = rot_temp_stars[0]\n",
    "    \n",
    "    #performs the rest of the Star Positioning function\n",
    "    \n",
    "    to_draw_original = testImage.copy()\n",
    "    to_draw_original = cv2.cvtColor(to_draw_original, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    to_draw_temp = rotated_template.copy()\n",
    "    to_draw_temp = cv2.cvtColor(to_draw_temp, cv2.COLOR_GRAY2BGR)\n",
    "       \n",
    "    #print(cX,cY)\n",
    "    \n",
    "    confidence = []\n",
    "    \n",
    "    max_no_of_stars = min(len(rot_temp_stars),len(destinationStars))\n",
    "    \n",
    "    for x in range(0,max_no_of_stars):\n",
    "        \n",
    "        '''\n",
    "        colour = random.randint(1,255)\n",
    "        cv2.drawContours(to_draw_original, destinationStars[x], -1, (colour,59,colour),10)\n",
    "        cv2.drawContours(to_draw_temp, rot_temp_stars[x], -1, (colour,59,colour),10)\n",
    "        '''\n",
    "        #print(destinationStars[x][0],rot_temp_stars[x][0])\n",
    "        \n",
    "        #print(testImage[rot_temp_stars[x][0][0][1],rot_temp_stars[x][0][0][0]])\n",
    "        #print(testImage[destinationStars[x][0][0][1],destinationStars[x][0][0][0]])\n",
    "        \n",
    "        lit = checkNeighbourhood(rot_temp_stars[x],testImage)\n",
    "        confidence.append(lit)\n",
    "    \n",
    "    norm_confidence = confidence.count(255)/len(confidence)\n",
    "        \n",
    "    #print(confidence.count(255)/len(confidence))\n",
    "    \n",
    "    final = cv2.hconcat([testImage,rotated_template])\n",
    "    final2 = cv2.hconcat([to_draw_original,to_draw_temp])\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    cv2.imshow(\"Rotated Template\",final)\n",
    "    cv2.waitKey(0)\n",
    "    ''''''\n",
    "    cv2.imshow(\"Rotated Template\",final2)\n",
    "    cv2.waitKey(0)'''\n",
    "    \n",
    "    return norm_confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drawConstellation(destinationStars,image_name,template_name,permute):\n",
    "    \n",
    "    #loads the template image of the predicted template's lines.\n",
    "    lines = cv2.imread(\"ConstellationLines/\"+template_name,1)\n",
    "    \n",
    "    #loads the original test image\n",
    "    original_image = cv2.imread(\"Dataset/\"+image_name,1)\n",
    "    \n",
    "    #only extract RED values, so we only plot the red colours within the template.\n",
    "    image_copy = lines.copy()\n",
    "    image_copy[:, :, 0] = 0\n",
    "    image_copy[:, :, 1] = 0\n",
    "    \n",
    "    template = cv2.imread(\"TemplateDataset/\"+template_name,0)\n",
    "\n",
    "    templateStars = findFourLargestStar(template)\n",
    "    \n",
    "    #performs the process of locating the four brightest stars on both images and then transforming the template \n",
    "    pts_source = np.array([templateStars[0],templateStars[1],templateStars[2],templateStars[3]])\n",
    "    \n",
    "    if permute == False:\n",
    "        pts_destination = np.array([destinationStars[0],destinationStars[1],destinationStars[2],destinationStars[3]]) \n",
    "\n",
    "    else:\n",
    "        permutations_list = list(permutations([0,1,2,3]))\n",
    "    \n",
    "        prev_best = 9999\n",
    "\n",
    "        for z in range(0,len(permutations_list)):\n",
    "            first = permutations_list[z][0]\n",
    "            second = permutations_list[z][1]\n",
    "            third = permutations_list[z][2]\n",
    "            fourth = permutations_list[z][3]\n",
    "            pts_destination = np.array([destinationStars[first],destinationStars[second],destinationStars[third],destinationStars[fourth]]) \n",
    "            h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "\n",
    "            rotated_template = cv2.warpPerspective(template, h, (original_image.shape[1],original_image.shape[0]))\n",
    "            rot_temp_stars = findFourLargestStar(rotated_template)\n",
    "\n",
    "            largestStar = rot_temp_stars[0]\n",
    "            matching = cv2.matchShapes(largestStar,destinationStars[0],cv2.CONTOURS_MATCH_I1,0.0)\n",
    "\n",
    "            if matching < prev_best:\n",
    "                prev_best = matching\n",
    "                best_index = z\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        first = permutations_list[best_index][0]\n",
    "        second = permutations_list[best_index][1]\n",
    "        third = permutations_list[best_index][2]\n",
    "        fourth = permutations_list[best_index][3]\n",
    "        pts_destination = np.array([destinationStars[first],destinationStars[second],destinationStars[third],destinationStars[fourth]]) \n",
    "        \n",
    "    h, status = cv2.findHomography(pts_source, pts_destination)\n",
    "\n",
    "    rotated_lines = cv2.warpPerspective(lines, h, (original_image.shape[1],original_image.shape[0]))\n",
    "    rotated_lines[:, :, 0] = 0\n",
    "    rotated_lines[:, :, 1] = 0\n",
    "    \n",
    "    #draws the rotated template onto the original image\n",
    "    result = cv2.addWeighted(original_image,0.7,rotated_lines,0.3,0)\n",
    "    \n",
    "    '''cv2.imshow(\"Connect The Dots\",result)\n",
    "    cv2.waitKey(0)\n",
    "    '''\n",
    "    #saves the results \n",
    "    cv2.imwrite(\"Results/\"+image_name,result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Cassiopeia0.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia1.png  Matched: Cassiopeia.PNG\n",
      "Actual: Cassiopeia10.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia11.png  Matched: Gemini.PNG\n",
      "Actual: Cassiopeia12.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia13.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia14.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia15.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia16.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia17.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia18.png  Matched: Libra.PNG\n",
      "Actual: Cassiopeia19.png  Matched: Cassiopeia.PNG\n",
      "Actual: Cassiopeia2.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia3.png  Matched: Gemini.PNG\n",
      "Actual: Cassiopeia4.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia5.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia6.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia7.png  Matched: Cassiopeia.PNG\n",
      "Actual: Cassiopeia8.png  Matched: Hercules.PNG\n",
      "Actual: Cassiopeia9.png  Matched: Hercules.PNG\n",
      "Actual: Gemini0.png  Matched: Gemini.PNG\n",
      "Actual: Gemini1.png  Matched: Gemini.PNG\n",
      "Actual: Gemini10.png  Matched: Gemini.PNG\n",
      "Actual: Gemini11.png  Matched: Gemini.PNG\n",
      "Actual: Gemini12.png  Matched: Gemini.PNG\n",
      "Actual: Gemini13.png  Matched: Gemini.PNG\n",
      "Actual: Gemini14.png  Matched: Gemini.PNG\n",
      "Actual: Gemini15.png  Matched: Gemini.PNG\n",
      "Actual: Gemini16.png  Matched: Gemini.PNG\n",
      "Actual: Gemini17.png  Matched: Gemini.PNG\n",
      "Actual: Gemini18.png  Matched: Gemini.PNG\n",
      "Actual: Gemini19.png  Matched: Gemini.PNG\n",
      "Actual: Gemini2.png  Matched: Gemini.PNG\n",
      "Actual: Gemini3.png  Matched: Gemini.PNG\n",
      "Actual: Gemini4.png  Matched: Gemini.PNG\n",
      "Actual: Gemini5.png  Matched: Gemini.PNG\n",
      "Actual: Gemini6.png  Matched: Gemini.PNG\n",
      "Actual: Gemini7.png  Matched: Gemini.PNG\n",
      "Actual: Gemini8.png  Matched: Gemini.PNG\n",
      "Actual: Gemini9.png  Matched: Gemini.PNG\n",
      "Actual: Hercules0.png  Matched: Hercules.PNG\n",
      "Actual: Hercules1.png  Matched: Hercules.PNG\n",
      "Actual: Hercules10.png  Matched: Hercules.PNG\n",
      "Actual: Hercules11.png  Matched: Hercules.PNG\n",
      "Actual: Hercules12.png  Matched: Hercules.PNG\n",
      "Actual: Hercules13.png  Matched: Gemini.PNG\n",
      "Actual: Hercules14.png  Matched: Hercules.PNG\n",
      "Actual: Hercules15.png  Matched: Hercules.PNG\n",
      "Actual: Hercules16.png  Matched: Hercules.PNG\n",
      "Actual: Hercules17.png  Matched: Hercules.PNG\n",
      "Actual: Hercules18.png  Matched: Hercules.PNG\n",
      "Actual: Hercules19.png  Matched: Hercules.PNG\n",
      "Actual: Hercules2.png  Matched: Hercules.PNG\n",
      "Actual: Hercules3.png  Matched: Hercules.PNG\n",
      "Actual: Hercules4.png  Matched: Hercules.PNG\n",
      "Actual: Hercules5.png  Matched: Hercules.PNG\n",
      "Actual: Hercules6.png  Matched: Hercules.PNG\n",
      "Actual: Hercules7.png  Matched: Hercules.PNG\n",
      "Actual: Hercules8.png  Matched: Hercules.PNG\n",
      "Actual: Hercules9.png  Matched: Hercules.PNG\n",
      "Actual: LEo0.png  Matched: Hercules.PNG\n",
      "Actual: LEo1.png  Matched: Leo.PNG\n",
      "Actual: Leo10.png  Matched: Leo.PNG\n",
      "Actual: Leo11.png  Matched: Leo.PNG\n",
      "Actual: Leo12.png  Matched: Leo.PNG\n",
      "Actual: Leo13.png  Matched: Leo.PNG\n",
      "Actual: Leo14.png  Matched: Leo.PNG\n",
      "Actual: Leo15.png  Matched: Leo.PNG\n",
      "Actual: Leo16.png  Matched: Leo.PNG\n",
      "Actual: Leo17.png  Matched: Leo.PNG\n",
      "Actual: Leo18.png  Matched: Leo.PNG\n",
      "Actual: Leo19.png  Matched: Leo.PNG\n",
      "Actual: LEo2.png  Matched: Leo.PNG\n",
      "Actual: LEo3.png  Matched: Hercules.PNG\n",
      "Actual: LEo4.png  Matched: Leo.PNG\n",
      "Actual: LEo5.png  Matched: Leo.PNG\n",
      "Actual: LEo6.png  Matched: Leo.PNG\n",
      "Actual: LEo7.png  Matched: Leo.PNG\n",
      "Actual: LEo8.png  Matched: Leo.PNG\n",
      "Actual: LEo9.png  Matched: Leo.PNG\n",
      "Actual: Libra0.png  Matched: Libra.PNG\n",
      "Actual: Libra1.png  Matched: Libra.PNG\n",
      "Actual: Libra10.png  Matched: Libra.PNG\n",
      "Actual: Libra11.png  Matched: Libra.PNG\n",
      "Actual: Libra12.png  Matched: Libra.PNG\n",
      "Actual: Libra13.png  Matched: Libra.PNG\n",
      "Actual: Libra14.png  Matched: Libra.PNG\n",
      "Actual: Libra15.png  Matched: Libra.PNG\n",
      "Actual: Libra16.png  Matched: Libra.PNG\n",
      "Actual: Libra17.png  Matched: Libra.PNG\n",
      "Actual: Libra18.png  Matched: Libra.PNG\n",
      "Actual: Libra19.png  Matched: Libra.PNG\n",
      "Actual: Libra2.png  Matched: Libra.PNG\n",
      "Actual: Libra3.png  Matched: Libra.PNG\n",
      "Actual: Libra4.png  Matched: Libra.PNG\n",
      "Actual: Libra5.png  Matched: Libra.PNG\n",
      "Actual: Libra6.png  Matched: Libra.PNG\n",
      "Actual: Libra7.png  Matched: Libra.PNG\n",
      "Actual: Libra8.png  Matched: Hercules.PNG\n",
      "Actual: Libra9.png  Matched: Libra.PNG\n",
      "Actual: Perseus0.png  Matched: Perseus.PNG\n",
      "Actual: Perseus1.png  Matched: Cassiopeia.PNG\n",
      "Actual: Perseus10.png  Matched: Perseus.PNG\n",
      "Actual: Perseus11.png  Matched: Libra.PNG\n",
      "Actual: Perseus12.png  Matched: Libra.PNG\n",
      "Actual: Perseus13.png  Matched: Cassiopeia.PNG\n",
      "Actual: Perseus14.png  Matched: Perseus.PNG\n",
      "Actual: Perseus15.png  Matched: Libra.PNG\n",
      "Actual: Perseus16.png  Matched: Perseus.PNG\n",
      "Actual: Perseus17.png  Matched: Perseus.PNG\n",
      "Actual: Perseus18.png  Matched: Perseus.PNG\n",
      "Actual: Perseus19.png  Matched: Perseus.PNG\n",
      "Actual: Perseus2.png  Matched: Perseus.PNG\n",
      "Actual: Perseus3.png  Matched: Perseus.PNG\n",
      "Actual: Perseus4.png  Matched: Cassiopeia.PNG\n",
      "Actual: Perseus5.png  Matched: Cassiopeia.PNG\n",
      "Actual: Perseus6.png  Matched: Libra.PNG\n",
      "Actual: Perseus7.png  Matched: Perseus.PNG\n",
      "Actual: Perseus8.png  Matched: Perseus.PNG\n",
      "Actual: Perseus9.png  Matched: Perseus.PNG\n",
      "Actual: Phoenix0.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix1.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix10.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix11.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix12.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix13.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix14.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix15.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix16.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix17.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix18.png  Matched: UrsaMinor.PNG\n",
      "Actual: Phoenix19.png  Matched: UrsaMinor.PNG\n",
      "Actual: Phoenix2.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix3.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix4.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix5.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix6.png  Matched: Phoenix.PNG\n",
      "Actual: Phoenix7.png  Matched: UrsaMinor.PNG\n",
      "Actual: Phoenix8.png  Matched: Phoenix.PNG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Do Not Touch\n",
    "correct = 0\n",
    "total = 0\n",
    "start = time.time()\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "\n",
    "#Touch\n",
    "\n",
    "#Choose Method to execute, Contour Matching, Star Positioning or else defaults to Star Brightness Correction\n",
    "method = \"Contour Matching\"\n",
    "#True if you want to draw the results and save them in the results folder, False otherwise\n",
    "draw = True\n",
    "\n",
    "#loops through all images in the dataset\n",
    "for image in os.listdir(\"ProcessedDataset\"):\n",
    "    \n",
    "    total+=1\n",
    "    \n",
    "    test = cv2.imread(\"ProcessedDataset/\"+image,0)\n",
    "    #print(test.shape)\n",
    "    \n",
    "    testStars = findFourLargestStar(test)\n",
    "    \n",
    "    confidences = []\n",
    "    \n",
    "    contourMatches = []\n",
    "    \n",
    "    #checks it with every available template\n",
    "    for template in os.listdir(\"TemplateDataset\"):\n",
    "    \n",
    "        cassTemplate = cv2.imread(\"TemplateDataset/\"+template,0)\n",
    "\n",
    "        templateStars = findFourLargestStar(cassTemplate)\n",
    "        \n",
    "        if method == \"Contour Matching\":\n",
    "            permute = False\n",
    "            match = contourMatching(testStars,templateStars,test,cassTemplate)\n",
    "        \n",
    "            contourMatches.append(match)\n",
    "\n",
    "        elif method == \"Star Positioning\":\n",
    "            permute = False\n",
    "            confidence = starPositions(testStars,templateStars,test,cassTemplate)\n",
    "            confidences.append(confidence)\n",
    "        else:\n",
    "            permute = True\n",
    "            confidence = permutationsTemplateMatching(testStars,templateStars,test,cassTemplate)\n",
    "            confidences.append(confidence)\n",
    "    \n",
    "    \n",
    "    if method == \"Contour Matching\" :\n",
    "        smallest = min(contourMatches)\n",
    "        index = contourMatches.index(smallest)\n",
    "        \n",
    "        #regex expression to retrieve the name of the constellation only from the image\n",
    "        a = re.split('[^a-zA-Z]', image)\n",
    "        a = a[0].upper()\n",
    "\n",
    "        b = re.split('[^a-zA-Z]', os.listdir(\"TemplateDataset\")[index])\n",
    "        b = b[0].upper()\n",
    "\n",
    "        print(\"Actual:\",image,\" Matched:\",os.listdir(\"TemplateDataset\")[index])\n",
    "\n",
    "        actual.append(a)\n",
    "        predicted.append(b)\n",
    "\n",
    "        if a == b:\n",
    "            correct +=1 \n",
    "    else:\n",
    "        largest = max(confidences)\n",
    "\n",
    "        index = confidences.index(largest)\n",
    "\n",
    "        print(\"Actual:\",image,\" Matched:\",os.listdir(\"TemplateDataset\")[index],largest*100,\"%\")\n",
    "\n",
    "        a = re.split('[^a-zA-Z]', image)\n",
    "        a = a[0].upper()\n",
    "\n",
    "        b = re.split('[^a-zA-Z]', os.listdir(\"TemplateDataset\")[index])\n",
    "        b = b[0].upper()\n",
    "        \n",
    "        actual.append(a)\n",
    "        predicted.append(b)\n",
    "        \n",
    "        if a == b:\n",
    "            correct +=1 \n",
    "            \n",
    "    if draw == True:       \n",
    "        drawConstellation(testStars,image,os.listdir(\"TemplateDataset\")[index],permute)\n",
    "\n",
    "\n",
    "#constructs a confusion matrix based on the predicted and actual labels, and then displays it\n",
    "confusion = confusion_matrix(actual, predicted)\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion, [\"CASS\",\"GEM\",\"HERC\",\"LEO\",\"LIBR\",\"PERS\",\"PHNX\",\"URSA\"])\n",
    "\n",
    "\n",
    "display.plot()\n",
    "   \n",
    "print(\"Model Accuracy:\",correct/total*100)  \n",
    "print(\"Time Taken: \",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
